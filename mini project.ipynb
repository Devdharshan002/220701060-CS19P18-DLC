{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "V-zUWVDUHIg6",
        "outputId": "4d67a0aa-14cf-4d1d-f3d4-b44bdb902ecd"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'for' statement on line 25 (ipython-input-2458860995.py, line 26)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2458860995.py\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    encoded.append(word_index.get(w, 2))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 25\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "num_words = 10000\n",
        "maxlen = 200\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "model = Sequential([\n",
        " Embedding(input_dim=num_words, output_dim=64, input_length=maxlen),\n",
        " LSTM(64, dropout=0.3, recurrent_dropout=0.3),\n",
        " Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(\"\\nTraining the model...\\n\")\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_data=(x_test, y_test), verbose=1)\n",
        "print(\"\\nModel training complete!\\n\")\n",
        "word_index = imdb.get_word_index()\n",
        "def encode_review(text):\n",
        " words = text.lower().split()\n",
        " encoded = [1]\n",
        " for w in words:\n",
        " encoded.append(word_index.get(w, 2))\n",
        " return pad_sequences([encoded], maxlen=maxlen)\n",
        "while True:\n",
        " review = input(\"Enter a movie review (or type 'exit' to quit): \")\n",
        " if review.lower() == 'exit':\n",
        " print(\"Exiting the program. Goodbye!\")\n",
        " break\n",
        " pred = model.predict(encode_review(review))\n",
        "print(\"Predicted Sentiment:\", \"Positive ðŸ˜Š\" if pred[0][0] > 0.5 else \"Negative ðŸ˜ž\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsN6wuRNHcPJ",
        "outputId": "c4164193-7e2f-4e5e-d960-76334e953d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training the model...\n",
            "\n",
            "Epoch 1/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 323ms/step - accuracy: 0.6827 - loss: 0.5849 - val_accuracy: 0.8289 - val_loss: 0.3892\n",
            "Epoch 2/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 323ms/step - accuracy: 0.8505 - loss: 0.3584 - val_accuracy: 0.8290 - val_loss: 0.3888\n",
            "Epoch 3/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 350ms/step - accuracy: 0.8730 - loss: 0.3139 - val_accuracy: 0.8455 - val_loss: 0.3753\n",
            "\n",
            "Model training complete!\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
            "Predicted Sentiment: Negative ðŸ˜ž\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "num_words = 10000\n",
        "maxlen = 200\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "# Pad sequences\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Build model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=64, input_length=maxlen),\n",
        "    LSTM(64, dropout=0.3, recurrent_dropout=0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nTraining the model...\\n\")\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_data=(x_test, y_test), verbose=1)\n",
        "print(\"\\nModel training complete!\\n\")\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Encode review\n",
        "def encode_review(text):\n",
        "    words = text.lower().split()\n",
        "    encoded = [1]   # Start token\n",
        "    for w in words:\n",
        "        encoded.append(word_index.get(w, 2))  # OOV = 2\n",
        "    return pad_sequences([encoded], maxlen=maxlen)\n",
        "\n",
        "# Predict loop\n",
        "while True:\n",
        "    review = input(\"Enter a movie review (or type 'exit' to quit): \")\n",
        "\n",
        "    if review.lower() == 'exit':\n",
        "        print(\"Exiting the program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    pred = model.predict(encode_review(review))\n",
        "    print(\"Predicted Sentiment:\", \"Positive ðŸ˜Š\" if pred[0][0] > 0.5 else \"Negative ðŸ˜ž\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}